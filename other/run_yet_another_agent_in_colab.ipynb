{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "run_agent_in_colab.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NiklasZ/ece-239-as-micro-rts-project/blob/master/run_agent_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to run Micro-RTS in Colab:\n",
    "1. Upload relevant python files to Google Colab instance (can drag and drop them).\n",
    "2. On prompt, authenticate your weights and biases (`wandb`) account.\n",
    "\n",
    "Note: this could probably be automated if some feels like writing the bash commands.\n",
    "\n"
   ],
   "metadata": {
    "id": "CiH8ON0QoT8l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Set these before running!\n",
    "file_name = '4_transform_weight_critic.py'\n",
    "\n",
    "# Set for resuming runs\n",
    "resume = True\n",
    "resume_id = 'f5z4www5'\n",
    "\n",
    "# Set for new runs\n",
    "experiment_name ='testing-refactor-resume' # Will be suffixed onto file_name (without extension)\n",
    "sparse_rewards = True\n",
    "transformer_layers = 8\n",
    "feed_forward_neurons = 1024\n",
    "user_name='N'\n",
    "print(user_name, experiment_name, file_name)"
   ],
   "metadata": {
    "id": "0bZoTB2B47N5"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set `torchelastic==0.2.0` in `requirements.txt`. Colab doesn't seem to have a newer version\n",
    "!sed -i 's/torchelastic==0.2.2/torchelastic==0.2.0/' requirements.txt\n",
    "!grep 'torchelastic' requirements.txt\n",
    "\n",
    "# Disable all calls of `env.render()` or `envs.render()` in your code as Colab can't display the game board. \n",
    "# If this fails, you'll see this error: \n",
    "# \"No X11 DISPLAY variable was set, but this program performed an this program performed an operation which requires it.\"\"\n",
    "!sed -i 's/env.render()/#env.render()/' $file_name\n",
    "!sed -i 's/envs.render()/#env.render()/' $file_name\n",
    "!grep 'env.render()' $file_name\n",
    "!grep 'envs.render()' $file_name"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2le3mvse4Wei",
    "outputId": "6c84a30d-609a-404c-d67f-ddfddb72e104"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torchelastic==0.2.0\n",
      "        ##env.render()\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWQYnCkWhjnM",
    "outputId": "6b885d57-0e5e-44d9-d3b8-8979fad0b9e1"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: absl-py==0.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: cachetools==4.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.2.1)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2020.12.5)\n",
      "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: cleanrl==0.4.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: cloudpickle==1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: configparser==5.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (5.0.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: dacite==1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.6.0)\n",
      "Requirement already satisfied: dnspython==2.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (2.1.0)\n",
      "Requirement already satisfied: docker-pycreds==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.4.0)\n",
      "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.18.2)\n",
      "Requirement already satisfied: gitdb==4.0.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.0.7)\n",
      "Requirement already satisfied: GitPython==3.1.14 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (3.1.14)\n",
      "Requirement already satisfied: google-auth==1.28.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.4.4)\n",
      "Requirement already satisfied: grpcio==1.37.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.37.0)\n",
      "Requirement already satisfied: gym==0.17.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.17.3)\n",
      "Requirement already satisfied: gym-microrts==0.3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.3.2)\n",
      "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (2.10)\n",
      "Requirement already satisfied: JPype1==1.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.1)\n",
      "Requirement already satisfied: Markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (3.3.4)\n",
      "Requirement already satisfied: matplotlib==3.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (3.4.1)\n",
      "Requirement already satisfied: numpy==1.19.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (1.19.2)\n",
      "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 27)) (3.1.0)\n",
      "Requirement already satisfied: pandas==1.2.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (1.2.3)\n",
      "Requirement already satisfied: pathtools==0.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (0.1.2)\n",
      "Requirement already satisfied: Pillow==8.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (8.2.0)\n",
      "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (2.3)\n",
      "Requirement already satisfied: protobuf==3.15.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 32)) (3.15.8)\n",
      "Requirement already satisfied: psutil==5.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (5.8.0)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (0.2.8)\n",
      "Requirement already satisfied: pyglet==1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (1.5.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 37)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 38)) (2.8.1)\n",
      "Requirement already satisfied: python-etcd==0.4.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 39)) (0.4.5)\n",
      "Requirement already satisfied: pytz==2021.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 40)) (2021.1)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (5.4.1)\n",
      "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (2.25.1)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 43)) (1.3.0)\n",
      "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 44)) (4.7.2)\n",
      "Requirement already satisfied: scipy==1.6.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 45)) (1.6.2)\n",
      "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 46)) (0.11.1)\n",
      "Requirement already satisfied: sentry-sdk==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 47)) (1.0.0)\n",
      "Requirement already satisfied: shortuuid==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 48)) (1.0.1)\n",
      "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 49)) (1.15.0)\n",
      "Requirement already satisfied: smmap==4.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 50)) (4.0.0)\n",
      "Requirement already satisfied: stable-baselines3==1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 51)) (1.0)\n",
      "Requirement already satisfied: subprocess32==3.5.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 52)) (3.5.4)\n",
      "Requirement already satisfied: tensorboard==2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 53)) (2.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 54)) (1.8.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 55)) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchelastic==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 56)) (0.2.0)\n",
      "Requirement already satisfied: torchtext==0.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 57)) (0.12.0)\n",
      "Requirement already satisfied: torchvision==0.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 58)) (0.12.0+cu113)\n",
      "Requirement already satisfied: tqdm==4.60.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 59)) (4.60.0)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 60)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3==1.26.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 61)) (1.26.4)\n",
      "Requirement already satisfied: wandb==0.10.24 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 62)) (0.10.24)\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 63)) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.28.1->-r requirements.txt (line 16)) (57.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Markdown==3.3.4->-r requirements.txt (line 24)) (4.11.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.4.1->-r requirements.txt (line 53)) (0.37.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Markdown==3.3.4->-r requirements.txt (line 24)) (3.8.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEM9h53AgwFi",
    "outputId": "6fea8821-e1bf-4e17-8ece-c421deaa2db4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running experiment 'Niklas_ppo_diverse_impalaAgain_1_1653745623_3tccm8da'\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (1) Create a W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (2) Use an existing W&B account\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: (3) Don't visualize my results\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Enter your choice: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You chose 'Use an existing W&B account'\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter: \n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.10.24\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mNiklas_ppo_diverse_impalaAgain_1_1653745623_3tccm8da\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ece-239-as/cleanRL\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ece-239-as/cleanRL/runs/3tccm8da\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in /content/wandb/run-20220528_134800-3tccm8da\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "/usr/local/lib/python3.7/dist-packages/gym_microrts/microrts/maps/8x8/basesWorkers8x8.xml\n",
      "[Lai.rewardfunction.RewardFunctionInterface;@62ee68d8\n",
      "global_step=4464, episode_reward=-9.800000190734863\n",
      "global_step=6264, episode_reward=-9.800000190734863\n",
      "global_step=6288, episode_reward=-9.800000190734863\n",
      "global_step=7128, episode_reward=-3.0\n",
      "global_step=7416, episode_reward=1.0\n",
      "global_step=7440, episode_reward=0.0\n",
      "global_step=7584, episode_reward=1.0\n",
      "global_step=8112, episode_reward=-0.8000001907348633\n",
      "global_step=8160, episode_reward=6.0\n",
      "global_step=8184, episode_reward=3.0\n",
      "global_step=8496, episode_reward=0.0\n",
      "global_step=8520, episode_reward=1.0\n",
      "global_step=8928, episode_reward=-9.800000190734863\n",
      "global_step=9744, episode_reward=5.0\n",
      "global_step=9936, episode_reward=6.0\n",
      "global_step=10632, episode_reward=8.0\n",
      "Steps per sec: 802\n",
      "global_step=12600, episode_reward=-7.800000190734863\n",
      "global_step=12768, episode_reward=10.0\n",
      "global_step=12888, episode_reward=5.0\n",
      "global_step=13416, episode_reward=-2.0\n",
      "global_step=13488, episode_reward=-8.800000190734863\n",
      "global_step=13560, episode_reward=-1.0\n",
      "global_step=14448, episode_reward=-9.800000190734863\n",
      "global_step=14880, episode_reward=-9.800000190734863\n",
      "global_step=14952, episode_reward=7.0\n",
      "global_step=15048, episode_reward=4.0\n",
      "global_step=15408, episode_reward=5.0\n",
      "global_step=16152, episode_reward=-4.0\n",
      "global_step=16848, episode_reward=-1.0\n",
      "global_step=17784, episode_reward=-1.0\n",
      "global_step=18072, episode_reward=1.0\n",
      "global_step=18480, episode_reward=-9.800000190734863\n",
      "global_step=18504, episode_reward=2.0\n",
      "global_step=19056, episode_reward=0.0\n",
      "global_step=19224, episode_reward=-8.800000190734863\n",
      "global_step=19368, episode_reward=-8.800000190734863\n",
      "global_step=19416, episode_reward=4.0\n",
      "global_step=19824, episode_reward=2.0\n",
      "global_step=20160, episode_reward=1.0\n",
      "global_step=21360, episode_reward=5.0\n",
      "global_step=21888, episode_reward=-2.0\n",
      "global_step=22512, episode_reward=1.0\n",
      "global_step=22800, episode_reward=3.0\n",
      "global_step=24240, episode_reward=1.0\n",
      "global_step=24504, episode_reward=-7.800000190734863\n",
      "global_step=24576, episode_reward=1.0\n",
      "Steps per sec: 938\n",
      "global_step=25056, episode_reward=3.0\n",
      "global_step=25632, episode_reward=17.0\n",
      "global_step=25776, episode_reward=-9.800000190734863\n",
      "global_step=26376, episode_reward=-8.800000190734863\n",
      "global_step=26952, episode_reward=4.0\n",
      "global_step=27336, episode_reward=0.0\n",
      "global_step=27384, episode_reward=9.0\n",
      "global_step=27840, episode_reward=27.0\n",
      "global_step=27888, episode_reward=-7.800000190734863\n",
      "global_step=28056, episode_reward=21.0\n",
      "global_step=28296, episode_reward=0.0\n",
      "global_step=29496, episode_reward=-2.0\n",
      "global_step=29592, episode_reward=9.0\n",
      "global_step=30024, episode_reward=9.0\n",
      "global_step=31008, episode_reward=-8.800000190734863\n",
      "global_step=31440, episode_reward=4.0\n",
      "global_step=32328, episode_reward=10.0\n",
      "global_step=32952, episode_reward=-7.800000190734863\n",
      "global_step=33240, episode_reward=8.0\n",
      "global_step=33288, episode_reward=-8.800000190734863\n",
      "global_step=33960, episode_reward=9.0\n",
      "global_step=34248, episode_reward=-9.800000190734863\n",
      "global_step=34752, episode_reward=1.0\n",
      "global_step=35736, episode_reward=5.0\n",
      "global_step=36048, episode_reward=-8.800000190734863\n",
      "global_step=36168, episode_reward=4.0\n",
      "Steps per sec: 992\n",
      "global_step=36936, episode_reward=14.0\n",
      "global_step=37248, episode_reward=-9.800000190734863\n",
      "global_step=37488, episode_reward=-7.800000190734863\n",
      "global_step=37704, episode_reward=7.0\n",
      "global_step=37872, episode_reward=-8.800000190734863\n",
      "global_step=37992, episode_reward=11.0\n",
      "global_step=38064, episode_reward=4.0\n",
      "global_step=38280, episode_reward=-7.800000190734863\n",
      "global_step=39216, episode_reward=-8.800000190734863\n",
      "global_step=39408, episode_reward=5.0\n",
      "global_step=40200, episode_reward=-7.800000190734863\n",
      "global_step=40512, episode_reward=0.0\n",
      "global_step=41088, episode_reward=3.0\n",
      "global_step=41664, episode_reward=8.0\n",
      "global_step=42480, episode_reward=-9.800000190734863\n",
      "global_step=42840, episode_reward=6.0\n",
      "global_step=43296, episode_reward=1.0\n",
      "global_step=44160, episode_reward=5.0\n",
      "global_step=44400, episode_reward=0.0\n",
      "global_step=45672, episode_reward=2.0\n",
      "global_step=45744, episode_reward=0.0\n",
      "global_step=45792, episode_reward=-2.0\n",
      "global_step=45936, episode_reward=12.0\n",
      "global_step=46104, episode_reward=2.0\n",
      "global_step=46320, episode_reward=-2.0\n",
      "global_step=46824, episode_reward=10.0\n",
      "global_step=47040, episode_reward=-7.800000190734863\n",
      "global_step=47280, episode_reward=2.0\n",
      "global_step=48000, episode_reward=53.0\n",
      "global_step=48336, episode_reward=-7.800000190734863\n",
      "global_step=48888, episode_reward=4.0\n",
      "Steps per sec: 1028\n",
      "global_step=49224, episode_reward=3.0\n",
      "global_step=49368, episode_reward=-9.800000190734863\n",
      "global_step=49512, episode_reward=-9.800000190734863\n",
      "global_step=49728, episode_reward=6.0\n",
      "global_step=49872, episode_reward=7.0\n",
      "global_step=50064, episode_reward=5.0\n",
      "global_step=50280, episode_reward=-9.800000190734863\n",
      "global_step=51168, episode_reward=-1.0\n",
      "global_step=52080, episode_reward=-8.800000190734863\n",
      "global_step=52392, episode_reward=-5.800000190734863\n",
      "global_step=52488, episode_reward=6.0\n",
      "global_step=52536, episode_reward=-8.800000190734863\n",
      "global_step=52800, episode_reward=-7.800000190734863\n",
      "global_step=52896, episode_reward=-9.800000190734863\n",
      "global_step=52944, episode_reward=17.0\n",
      "global_step=53328, episode_reward=6.0\n",
      "global_step=53520, episode_reward=-8.800000190734863\n",
      "global_step=54336, episode_reward=4.0\n",
      "global_step=55800, episode_reward=-9.800000190734863\n",
      "global_step=55896, episode_reward=9.0\n",
      "global_step=56592, episode_reward=0.0\n",
      "global_step=57384, episode_reward=6.0\n",
      "global_step=57408, episode_reward=-9.800000190734863\n",
      "global_step=57504, episode_reward=-9.800000190734863\n",
      "Build.execute: something weird just happened Worker(9)(1, (5,7), 1, 0) builds at 4,7\n",
      "global_step=58488, episode_reward=-7.800000190734863\n",
      "global_step=58872, episode_reward=-8.800000190734863\n",
      "global_step=59544, episode_reward=-8.800000190734863\n",
      "global_step=60192, episode_reward=7.0\n",
      "global_step=61224, episode_reward=2.0\n",
      "Steps per sec: 1050\n",
      "global_step=61560, episode_reward=1.0\n",
      "global_step=61608, episode_reward=6.0\n",
      "global_step=61872, episode_reward=-9.800000190734863\n",
      "global_step=61920, episode_reward=5.0\n",
      "global_step=62184, episode_reward=-9.800000190734863\n",
      "global_step=62904, episode_reward=11.0\n",
      "global_step=63072, episode_reward=-7.800000190734863\n",
      "global_step=64008, episode_reward=14.0\n",
      "global_step=64032, episode_reward=6.0\n",
      "global_step=65088, episode_reward=-8.800000190734863\n",
      "global_step=65112, episode_reward=10.0\n",
      "global_step=65496, episode_reward=10.0\n",
      "global_step=66336, episode_reward=-9.800000190734863\n",
      "global_step=66576, episode_reward=-7.800000190734863\n",
      "global_step=66624, episode_reward=4.0\n",
      "global_step=67368, episode_reward=-9.800000190734863\n",
      "global_step=67512, episode_reward=-4.0\n",
      "global_step=67752, episode_reward=6.0\n",
      "global_step=67800, episode_reward=-8.800000190734863\n",
      "global_step=68328, episode_reward=5.0\n",
      "global_step=68928, episode_reward=13.0\n",
      "global_step=70440, episode_reward=16.0\n",
      "global_step=70824, episode_reward=4.0\n",
      "global_step=70848, episode_reward=1.3999996185302734\n",
      "global_step=70968, episode_reward=0.0\n",
      "global_step=71448, episode_reward=-3.8000001907348633\n",
      "global_step=71472, episode_reward=-7.800000190734863\n",
      "global_step=71736, episode_reward=3.0\n",
      "global_step=72360, episode_reward=11.0\n",
      "global_step=73704, episode_reward=7.0\n",
      "Steps per sec: 1064\n",
      "global_step=73896, episode_reward=2.0\n",
      "global_step=74208, episode_reward=-8.800000190734863\n",
      "global_step=75288, episode_reward=8.0\n",
      "global_step=75336, episode_reward=-7.800000190734863\n",
      "global_step=75624, episode_reward=6.0\n",
      "global_step=76080, episode_reward=3.0\n",
      "global_step=76344, episode_reward=0.0\n",
      "global_step=76416, episode_reward=2.0\n",
      "global_step=77160, episode_reward=-9.800000190734863\n",
      "global_step=77208, episode_reward=4.0\n",
      "global_step=77448, episode_reward=48.0\n",
      "global_step=77640, episode_reward=-7.800000190734863\n",
      "global_step=77688, episode_reward=-7.800000190734863\n",
      "global_step=77976, episode_reward=12.0\n",
      "global_step=79056, episode_reward=18.0\n",
      "global_step=79152, episode_reward=6.0\n",
      "global_step=79752, episode_reward=-9.800000190734863\n",
      "global_step=81888, episode_reward=3.0\n",
      "global_step=82080, episode_reward=-2.0\n",
      "global_step=82176, episode_reward=0.0\n",
      "global_step=82920, episode_reward=-8.800000190734863\n",
      "global_step=83040, episode_reward=0.0\n",
      "global_step=83256, episode_reward=-7.800000190734863\n",
      "global_step=83304, episode_reward=12.0\n",
      "global_step=83568, episode_reward=-8.800000190734863\n",
      "global_step=84072, episode_reward=-9.800000190734863\n",
      "global_step=84600, episode_reward=0.0\n",
      "global_step=84768, episode_reward=3.0\n",
      "global_step=85008, episode_reward=-9.800000190734863\n",
      "global_step=85272, episode_reward=10.0\n",
      "global_step=85536, episode_reward=65.0\n",
      "global_step=85752, episode_reward=4.0\n",
      "Steps per sec: 1072\n",
      "global_step=88296, episode_reward=10.0\n",
      "global_step=88920, episode_reward=6.0\n",
      "global_step=89040, episode_reward=-8.800000190734863\n",
      "global_step=89808, episode_reward=-7.800000190734863\n",
      "global_step=89928, episode_reward=-8.800000190734863\n",
      "global_step=90096, episode_reward=16.0\n",
      "global_step=90672, episode_reward=28.0\n",
      "global_step=90744, episode_reward=6.0\n",
      "global_step=91368, episode_reward=-8.800000190734863\n",
      "global_step=91416, episode_reward=2.0\n",
      "global_step=91512, episode_reward=0.0\n",
      "global_step=91656, episode_reward=6.0\n",
      "global_step=91800, episode_reward=5.0\n",
      "global_step=91944, episode_reward=2.0\n",
      "global_step=92496, episode_reward=3.0\n",
      "global_step=92760, episode_reward=4.0\n",
      "global_step=94200, episode_reward=5.0\n",
      "global_step=94344, episode_reward=10.0\n",
      "global_step=94416, episode_reward=7.0\n",
      "global_step=95256, episode_reward=40.0\n",
      "global_step=95304, episode_reward=-8.800000190734863\n",
      "global_step=95496, episode_reward=34.0\n",
      "global_step=95808, episode_reward=-8.800000190734863\n",
      "global_step=96288, episode_reward=-9.800000190734863\n",
      "global_step=97248, episode_reward=-8.800000190734863\n",
      "global_step=97368, episode_reward=-9.800000190734863\n",
      "global_step=97728, episode_reward=-8.800000190734863\n",
      "global_step=97848, episode_reward=15.0\n",
      "global_step=98016, episode_reward=2.0\n",
      "Steps per sec: 1077\n",
      "global_step=99384, episode_reward=3.0\n",
      "global_step=99480, episode_reward=1.0\n",
      "global_step=100104, episode_reward=10.0\n",
      "global_step=100608, episode_reward=-9.800000190734863\n",
      "global_step=101568, episode_reward=18.0\n",
      "global_step=102408, episode_reward=-1.0\n",
      "global_step=103992, episode_reward=1.0\n",
      "global_step=104016, episode_reward=-8.800000190734863\n",
      "global_step=104040, episode_reward=-8.800000190734863\n",
      "global_step=104256, episode_reward=11.0\n",
      "global_step=104352, episode_reward=-8.800000190734863\n",
      "global_step=104424, episode_reward=4.0\n",
      "global_step=104832, episode_reward=12.0\n",
      "global_step=105168, episode_reward=6.0\n",
      "global_step=105504, episode_reward=6.0\n",
      "global_step=106536, episode_reward=20.0\n",
      "global_step=106560, episode_reward=2.0\n",
      "global_step=107592, episode_reward=29.0\n",
      "global_step=108576, episode_reward=8.0\n",
      "global_step=108768, episode_reward=-8.800000190734863\n",
      "global_step=109128, episode_reward=-9.800000190734863\n",
      "global_step=109512, episode_reward=3.0\n",
      "global_step=110304, episode_reward=-9.800000190734863\n",
      "Steps per sec: 1080\n",
      "global_step=111072, episode_reward=11.0\n",
      "global_step=111816, episode_reward=-8.800000190734863\n",
      "global_step=112008, episode_reward=13.0\n",
      "global_step=112296, episode_reward=20.0\n",
      "global_step=112464, episode_reward=-1.0\n",
      "global_step=112776, episode_reward=7.0\n",
      "global_step=112800, episode_reward=16.0\n",
      "global_step=115464, episode_reward=8.0\n",
      "global_step=115608, episode_reward=2.1999998092651367\n",
      "global_step=116424, episode_reward=1.0\n",
      "global_step=116496, episode_reward=8.0\n",
      "global_step=116856, episode_reward=7.0\n",
      "global_step=117192, episode_reward=8.0\n",
      "global_step=117240, episode_reward=5.0\n",
      "global_step=117408, episode_reward=60.0\n",
      "global_step=117768, episode_reward=-7.800000190734863\n",
      "global_step=117792, episode_reward=3.0\n",
      "global_step=119112, episode_reward=-8.800000190734863\n",
      "global_step=119448, episode_reward=13.0\n",
      "global_step=119616, episode_reward=12.0\n",
      "global_step=119712, episode_reward=3.0\n",
      "global_step=119760, episode_reward=3.0\n",
      "global_step=119784, episode_reward=4.0\n",
      "global_step=121296, episode_reward=45.0\n",
      "global_step=122328, episode_reward=14.0\n",
      "Steps per sec: 1088\n",
      "global_step=122952, episode_reward=11.0\n",
      "global_step=123744, episode_reward=15.0\n",
      "global_step=123984, episode_reward=-9.800000190734863\n",
      "global_step=124896, episode_reward=14.0\n",
      "global_step=125232, episode_reward=7.0\n",
      "global_step=125688, episode_reward=-8.800000190734863\n",
      "global_step=125736, episode_reward=19.0\n",
      "global_step=125928, episode_reward=2.0\n",
      "global_step=127416, episode_reward=11.0\n",
      "global_step=128304, episode_reward=2.0\n",
      "global_step=128448, episode_reward=6.0\n",
      "global_step=128736, episode_reward=5.0\n",
      "global_step=130344, episode_reward=-8.800000190734863\n",
      "global_step=130872, episode_reward=22.400001525878906\n",
      "global_step=131376, episode_reward=-7.800000190734863\n",
      "global_step=131568, episode_reward=0.0\n",
      "global_step=131616, episode_reward=-7.800000190734863\n",
      "global_step=131640, episode_reward=-7.800000190734863\n",
      "global_step=132120, episode_reward=-8.800000190734863\n",
      "global_step=133128, episode_reward=12.0\n",
      "global_step=133344, episode_reward=29.60000228881836\n",
      "global_step=133536, episode_reward=78.0\n",
      "global_step=133752, episode_reward=20.0\n",
      "global_step=133992, episode_reward=3.0\n",
      "global_step=134664, episode_reward=-9.800000190734863\n",
      "global_step=134928, episode_reward=8.200000762939453\n",
      "global_step=135096, episode_reward=27.0\n",
      "Steps per sec: 1092\n",
      "global_step=135240, episode_reward=-7.800000190734863\n",
      "global_step=136152, episode_reward=1.0\n",
      "global_step=136536, episode_reward=-9.800000190734863\n",
      "global_step=136920, episode_reward=112.0\n",
      "global_step=137208, episode_reward=6.0\n",
      "global_step=139032, episode_reward=1.0\n",
      "global_step=139440, episode_reward=14.0\n",
      "global_step=140760, episode_reward=-8.800000190734863\n",
      "global_step=141096, episode_reward=-8.800000190734863\n",
      "global_step=141384, episode_reward=-9.800000190734863\n",
      "global_step=141624, episode_reward=10.0\n",
      "global_step=141768, episode_reward=10.0\n",
      "global_step=142512, episode_reward=14.0\n",
      "global_step=142536, episode_reward=6.0\n",
      "global_step=143064, episode_reward=4.0\n",
      "global_step=144336, episode_reward=15.0\n",
      "global_step=145080, episode_reward=13.0\n",
      "global_step=145824, episode_reward=16.0\n",
      "global_step=145848, episode_reward=-9.800000190734863\n",
      "global_step=145920, episode_reward=-8.800000190734863\n",
      "global_step=146208, episode_reward=5.0\n",
      "global_step=146304, episode_reward=20.0\n",
      "global_step=147000, episode_reward=-9.800000190734863\n",
      "global_step=147048, episode_reward=-8.800000190734863\n",
      "global_step=147192, episode_reward=10.0\n",
      "global_step=147240, episode_reward=19.0\n",
      "global_step=147288, episode_reward=6.200000762939453\n",
      "Steps per sec: 1098\n",
      "global_step=148176, episode_reward=57.0\n",
      "global_step=148272, episode_reward=9.0\n",
      "global_step=149472, episode_reward=12.0\n",
      "global_step=150312, episode_reward=-9.800000190734863\n",
      "global_step=152304, episode_reward=-7.800000190734863\n",
      "global_step=152640, episode_reward=-7.800000190734863\n",
      "global_step=153672, episode_reward=-7.800000190734863\n",
      "global_step=153792, episode_reward=19.0\n",
      "global_step=154032, episode_reward=32.0\n",
      "global_step=154104, episode_reward=3.0\n",
      "global_step=154176, episode_reward=15.0\n",
      "global_step=154536, episode_reward=24.0\n",
      "global_step=154704, episode_reward=3.0\n",
      "global_step=156648, episode_reward=6.0\n",
      "global_step=156696, episode_reward=9.0\n",
      "global_step=159000, episode_reward=16.0\n",
      "global_step=159048, episode_reward=6.399999618530273\n",
      "global_step=159288, episode_reward=8.0\n",
      "Steps per sec: 1103\n",
      "global_step=160056, episode_reward=15.0\n",
      "global_step=160104, episode_reward=-8.800000190734863\n",
      "global_step=160536, episode_reward=-8.800000190734863\n",
      "global_step=160656, episode_reward=-7.800000190734863\n",
      "global_step=160728, episode_reward=-9.800000190734863\n",
      "global_step=161592, episode_reward=16.0\n",
      "global_step=162144, episode_reward=33.0\n",
      "global_step=162168, episode_reward=30.0\n",
      "global_step=162192, episode_reward=11.0\n",
      "global_step=162744, episode_reward=7.0\n",
      "global_step=163728, episode_reward=8.800003051757812\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=165336, episode_reward=-8.800000190734863\n",
      "global_step=165792, episode_reward=-7.800000190734863\n",
      "global_step=166488, episode_reward=43.0\n",
      "global_step=166608, episode_reward=-7.800000190734863\n",
      "global_step=166680, episode_reward=-7.800000190734863\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=166824, episode_reward=12.0\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=167040, episode_reward=6.400001525878906\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=167832, episode_reward=54.0\n",
      "global_step=168096, episode_reward=-7.800000190734863\n",
      "global_step=168192, episode_reward=-7.800000190734863\n",
      "global_step=169272, episode_reward=13.0\n",
      "global_step=169296, episode_reward=61.400001525878906\n",
      "global_step=169944, episode_reward=64.0\n",
      "global_step=170328, episode_reward=1.1999998092651367\n",
      "global_step=171648, episode_reward=3.1999998092651367\n",
      "Steps per sec: 1105\n",
      "global_step=172656, episode_reward=-7.800000190734863\n",
      "global_step=172848, episode_reward=32.000003814697266\n",
      "global_step=172872, episode_reward=-7.800000190734863\n",
      "global_step=172896, episode_reward=-9.800000190734863\n",
      "global_step=173040, episode_reward=7.0\n",
      "global_step=173688, episode_reward=6.0\n",
      "global_step=174048, episode_reward=14.0\n",
      "global_step=174456, episode_reward=-7.800000190734863\n",
      "global_step=174768, episode_reward=10.0\n",
      "global_step=175464, episode_reward=13.0\n",
      "global_step=175728, episode_reward=67.19999694824219\n",
      "global_step=177000, episode_reward=17.0\n",
      "global_step=178128, episode_reward=-7.800000190734863\n",
      "global_step=178344, episode_reward=13.0\n",
      "global_step=178656, episode_reward=7.0\n",
      "global_step=179280, episode_reward=-8.800000190734863\n",
      "global_step=179304, episode_reward=7.200000762939453\n",
      "global_step=180072, episode_reward=21.0\n",
      "global_step=181632, episode_reward=6.200000762939453\n",
      "global_step=182472, episode_reward=8.0\n",
      "global_step=182640, episode_reward=3.0\n",
      "global_step=183264, episode_reward=22.0\n",
      "Steps per sec: 1109\n",
      "global_step=184416, episode_reward=8.200000762939453\n",
      "global_step=184464, episode_reward=13.0\n",
      "global_step=187128, episode_reward=10.0\n",
      "global_step=187416, episode_reward=19.0\n",
      "global_step=187584, episode_reward=15.0\n",
      "global_step=187872, episode_reward=21.0\n",
      "global_step=187968, episode_reward=-8.800000190734863\n",
      "global_step=188280, episode_reward=65.0\n",
      "global_step=188496, episode_reward=8.0\n",
      "global_step=188544, episode_reward=31.0\n",
      "global_step=188664, episode_reward=-7.800000190734863\n",
      "global_step=188712, episode_reward=75.0\n",
      "global_step=188952, episode_reward=18.0\n",
      "global_step=189192, episode_reward=14.0\n",
      "global_step=190440, episode_reward=5.0\n",
      "global_step=190632, episode_reward=60.0\n",
      "global_step=193344, episode_reward=25.0\n",
      "global_step=193488, episode_reward=31.0\n",
      "global_step=193560, episode_reward=27.60000228881836\n",
      "global_step=193584, episode_reward=-7.800000190734863\n",
      "global_step=193920, episode_reward=-8.800000190734863\n",
      "global_step=194040, episode_reward=21.0\n",
      "global_step=195720, episode_reward=10.0\n",
      "Steps per sec: 1114\n",
      "global_step=197592, episode_reward=5.0\n",
      "global_step=198600, episode_reward=44.0\n",
      "global_step=198648, episode_reward=14.0\n",
      "global_step=199512, episode_reward=5.0\n",
      "global_step=200256, episode_reward=46.0\n",
      "global_step=200280, episode_reward=-7.800000190734863\n",
      "global_step=200304, episode_reward=-7.800000190734863\n",
      "global_step=200472, episode_reward=18.0\n",
      "global_step=200808, episode_reward=10.0\n",
      "global_step=201072, episode_reward=42.0\n",
      "global_step=201096, episode_reward=13.400001525878906\n",
      "global_step=201120, episode_reward=17.0\n",
      "global_step=201384, episode_reward=4.0\n",
      "global_step=202608, episode_reward=7.0\n",
      "Build.execute: something weird just happened Worker(5294)(1, (6,6), 1, 0) builds at 6,5\n",
      "global_step=203976, episode_reward=40.0\n",
      "global_step=204240, episode_reward=19.0\n",
      "global_step=205704, episode_reward=24.0\n",
      "global_step=206472, episode_reward=18.0\n",
      "global_step=206520, episode_reward=-8.800000190734863\n",
      "global_step=207072, episode_reward=-7.800000190734863\n",
      "global_step=207288, episode_reward=-7.800000190734863\n",
      "global_step=207408, episode_reward=-8.800000190734863\n",
      "global_step=207528, episode_reward=-7.800000190734863\n",
      "global_step=208176, episode_reward=15.0\n",
      "global_step=208776, episode_reward=16.0\n",
      "Steps per sec: 1116\n",
      "global_step=208968, episode_reward=-7.800000190734863\n",
      "global_step=211512, episode_reward=22.0\n",
      "global_step=212904, episode_reward=52.0\n",
      "global_step=212952, episode_reward=10.0\n",
      "global_step=213624, episode_reward=-8.800000190734863\n",
      "global_step=213960, episode_reward=2.0\n",
      "global_step=214632, episode_reward=-6.599999904632568\n",
      "global_step=214728, episode_reward=-7.800000190734863\n",
      "global_step=214848, episode_reward=34.20000076293945\n",
      "global_step=215040, episode_reward=109.0\n",
      "global_step=216984, episode_reward=10.0\n",
      "global_step=217680, episode_reward=16.400001525878906\n",
      "global_step=217848, episode_reward=-7.800000190734863\n",
      "global_step=219216, episode_reward=15.0\n",
      "global_step=220152, episode_reward=-6.599999904632568\n",
      "global_step=220440, episode_reward=26.800003051757812\n",
      "Steps per sec: 1120\n",
      "global_step=221208, episode_reward=17.0\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=222216, episode_reward=31.0\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=223272, episode_reward=11.60000228881836\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=223632, episode_reward=78.19999694824219\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=225240, episode_reward=32.0\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=226392, episode_reward=18.400001525878906\n",
      "global_step=227064, episode_reward=43.0\n",
      "global_step=227616, episode_reward=36.20000076293945\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=227856, episode_reward=37.20000076293945\n",
      "global_step=228192, episode_reward=13.0\n",
      "global_step=228816, episode_reward=17.0\n",
      "global_step=229032, episode_reward=-7.800000190734863\n",
      "global_step=229440, episode_reward=34.0\n",
      "global_step=229584, episode_reward=6.200000762939453\n",
      "global_step=230304, episode_reward=16.200000762939453\n",
      "global_step=231360, episode_reward=10.400001525878906\n",
      "global_step=231624, episode_reward=6.0\n",
      "Steps per sec: 1124\n",
      "global_step=233808, episode_reward=26.0\n",
      "global_step=233832, episode_reward=61.400001525878906\n",
      "global_step=234168, episode_reward=-7.800000190734863\n",
      "global_step=234816, episode_reward=-5.800000190734863\n",
      "global_step=234936, episode_reward=10.0\n",
      "global_step=235440, episode_reward=11.0\n",
      "global_step=235776, episode_reward=27.0\n",
      "global_step=236160, episode_reward=8.0\n",
      "global_step=236880, episode_reward=41.0\n",
      "global_step=237336, episode_reward=-7.800000190734863\n",
      "global_step=239208, episode_reward=42.0\n",
      "global_step=240024, episode_reward=37.0\n",
      "global_step=241080, episode_reward=1.0\n",
      "global_step=241176, episode_reward=-7.800000190734863\n",
      "global_step=241200, episode_reward=42.0\n",
      "global_step=241296, episode_reward=-7.800000190734863\n",
      "global_step=241464, episode_reward=18.0\n",
      "global_step=241584, episode_reward=8.0\n",
      "global_step=242232, episode_reward=-7.800000190734863\n",
      "global_step=243480, episode_reward=27.400001525878906\n",
      "global_step=245328, episode_reward=8.0\n",
      "global_step=245376, episode_reward=16.0\n",
      "global_step=245592, episode_reward=14.400001525878906\n",
      "Steps per sec: 1126\n",
      "global_step=246648, episode_reward=75.19999694824219\n",
      "global_step=246744, episode_reward=8.400001525878906\n",
      "global_step=247248, episode_reward=-7.800000190734863\n",
      "global_step=247632, episode_reward=73.0\n",
      "global_step=247944, episode_reward=36.0\n",
      "global_step=249024, episode_reward=12.0\n",
      "global_step=249432, episode_reward=15.0\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=249480, episode_reward=-7.800000190734863\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=250512, episode_reward=9.400001525878906\n",
      "global_step=250584, episode_reward=49.0\n",
      "global_step=251568, episode_reward=3.0\n",
      "global_step=252408, episode_reward=-7.800000190734863\n",
      "global_step=252456, episode_reward=17.0\n",
      "global_step=252528, episode_reward=9.0\n",
      "WARNING: TrainDirection invalid direction\n",
      "global_step=253200, episode_reward=43.20000076293945\n",
      "global_step=253224, episode_reward=-7.800000190734863\n",
      "global_step=253728, episode_reward=0.39999961853027344\n",
      "global_step=254256, episode_reward=-8.800000190734863\n",
      "global_step=255336, episode_reward=-8.800000190734863\n",
      "global_step=255384, episode_reward=-7.800000190734863\n",
      "global_step=256896, episode_reward=29.60000228881836\n",
      "global_step=257496, episode_reward=30.0\n",
      "global_step=257760, episode_reward=64.0\n"
     ]
    }
   ],
   "source": [
    "name = f\"{file_name.split('.')[0]}_{experiment_name}\"\n",
    "if resume:\n",
    "  !python $file_name resume --run-id $resume_id\n",
    "else:\n",
    "  !python $file_name new --prod-mode --exp-name $name --gym-id $user_name --sparse-rewards $sparse_rewards --transformer-layers $transformer_layers --feed-forward-neurons $feed_forward_neurons\n",
    "print('Done')"
   ]
  }
 ]
}